{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/localhost/not-backed-up/spoendli/miniconda3/envs/ab/lib/python3.8/site-packages/Bio/SubsMat/__init__.py:126: BiopythonDeprecationWarning: Bio.SubsMat has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.substitution_matrices as a replacement, and contact the Biopython developers if you still need the Bio.SubsMat module.\n",
      "  warnings.warn(\n",
      "Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.\n"
     ]
    }
   ],
   "source": [
    "from ABDB import database as db\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from retrain_ablooper import *\n",
    "import torch\n",
    "import pandas as pd\n",
    "from rich import print as pprint\n",
    "from ABlooper import CDR_Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Own code for relaxing sturcutres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch settings\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "model = MaskDecoyGen(decoys=5).to(device = device).float()\n",
    "model.load_state_dict(torch.load('best_models/best_model-2804-Radam-5-2optim', map_location=torch.device(device)))\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "train = torch.load('train_data/train.pt')\n",
    "validation = torch.load('train_data/val.pt')\n",
    "test = torch.load('train_data/test.pt')\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(validation, \n",
    "                                             batch_size=batch_size,\n",
    "                                             num_workers=1,\n",
    "                                             shuffle=False,\n",
    "                                             pin_memory=True,\n",
    "                                             )\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test, \n",
    "                                              batch_size=batch_size,\n",
    "                                              num_workers=1,\n",
    "                                              shuffle=False,\n",
    "                                              pin_memory=True,\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaskDecoyGen(decoys=5).to(device = device).float()\n",
    "for i in range(5):\n",
    "    model.blocks[i].load_state_dict(torch.load(\"best_models/best_model-0305-Radam-1-2optim-1\", map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdb_select_hc_lc(pdb_text, chains):\n",
    "    '''\n",
    "    Returns only lines of a pdb file which correspond to the heavy or light chain of the antibody\n",
    "    '''\n",
    "    atoms = [line for line in pdb_text if line.split()[0] == 'ATOM']\n",
    "    pdb_text_hc_lc = [line for line in atoms if line.split()[4] in chains]\n",
    "    \n",
    "    return pdb_text_hc_lc\n",
    "    \n",
    "\n",
    "def produce_full_structures_of_val_set(val_dataloader, model, outdir='', relax=True, to_be_rewritten=[\"H1\", \"H2\", \"H3\", \"L1\", \"L2\", \"L3\"]):\n",
    "    '''\n",
    "    Produces full FAB structure for a dataset\n",
    "    '''\n",
    "    CDR_rmsds_not_relaxed = list()\n",
    "    CDR_rmsds_relaxes = list()\n",
    "    decoy_diversities = list()\n",
    "    order_of_pdbs = list()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for data in track(val_dataloader, description='predict val set'):\n",
    "\n",
    "            # predict sturcture using the model\n",
    "            coordinates, geomout, node_feature, mask, id = data['geomins'].float().to(device), data['geomouts'].float().to(device), data['encodings'].float().to(device), data['mask'].float().to(device), data['ids']\n",
    "            pred = model(node_feature, coordinates, mask)\n",
    "            CDR_rmsds_not_relaxed.append(rmsd_per_cdr(pred, node_feature, geomout).tolist())\n",
    "            pred = pred.squeeze() # remove batch dimension\n",
    "            \n",
    "            # get framework info from pdb file\n",
    "            pdb_id, heavy_c, light_c, pdb_file = get_info_from_id(id)\n",
    "            chains = [heavy_c, light_c]\n",
    "            order_of_pdbs.append(pdb_id)\n",
    "\n",
    "            with open(pdb_file) as file:\n",
    "                pdb_text = [line for line in file.readlines()]\n",
    "                \n",
    "            pdb_text = pdb_select_hc_lc(pdb_text, chains)\n",
    "\n",
    "            CDR_with_anchor_slices, atoms, CDR_text, CDR_sequences, CDR_numberings, CDR_start_atom_id = get_framework_info(pdb_text, chains)\n",
    "            \n",
    "            predicted_CDRs = {}\n",
    "            all_decoys = {}\n",
    "            decoy_diversity = {}\n",
    "\n",
    "            for i, CDR in enumerate(CDR_with_anchor_slices):\n",
    "                output_CDR = pred[:, node_feature[0, :, 30 + i] == 1.0]\n",
    "                all_decoys[CDR] = rearrange(output_CDR, \"b (i a) d -> b i a d\", a=4).cpu().numpy()\n",
    "                predicted_CDRs[CDR] = rearrange(output_CDR.mean(0), \"(i a) d -> i a d\", a=4).cpu().numpy()\n",
    "                decoy_diversity[CDR] = (output_CDR[None] - output_CDR[:, None]).pow(2).sum(-1).mean(-1).pow(\n",
    "                    1 / 2).sum().item() / 20\n",
    "            \n",
    "            decoy_diversities.append(list(decoy_diversity.values()))\n",
    "            \n",
    "            text_prediction_per_CDR = convert_predictions_into_text_for_each_CDR(CDR_start_atom_id, predicted_CDRs, CDR_sequences, CDR_numberings, CDR_with_anchor_slices)\n",
    "            old_text = pdb_text\n",
    "\n",
    "            for CDR in to_be_rewritten:\n",
    "                new = True\n",
    "                new_text = []\n",
    "                chain, CDR_slice = CDR_with_anchor_slices[CDR]\n",
    "                CDR_slice = (CDR_slice[0] + 2, CDR_slice[1] - 2)\n",
    "\n",
    "                for line in old_text:\n",
    "                    if not filt(line, chain, CDR_slice):\n",
    "                        new_text.append(line)\n",
    "                    elif new:\n",
    "                        new_text += text_prediction_per_CDR[CDR]\n",
    "                        new = False\n",
    "                    else:\n",
    "                        continue\n",
    "                old_text = new_text\n",
    "\n",
    "            header = [\n",
    "                \"REMARK    CDR LOOPS REMODELLED USING ABLOOPER                                   \\n\"]\n",
    "            new_text = \"\".join(header + old_text)\n",
    "\n",
    "            with open('pdbs/'+outdir+'/'+pdb_id+'-'+heavy_c+light_c+'.pdb', \"w+\") as file:\n",
    "                file.write(new_text)\n",
    "\n",
    "            with open('pdbs/'+outdir+'/'+pdb_id+'-'+heavy_c+light_c+'-true.pdb', \"w+\") as file:\n",
    "                file.write(\"\".join(pdb_text))\n",
    "\n",
    "            if relax:\n",
    "                relaxed_text = openmm_refine(old_text, CDR_with_anchor_slices)\n",
    "                header.append(\"REMARK    REFINEMENT DONE USING OPENMM\" + 42 * \" \" + \"\\n\")\n",
    "                relaxed_text = \"\".join(header + relaxed_text)\n",
    "\n",
    "                with open('pdbs/'+outdir+'/'+pdb_id+'-'+heavy_c+light_c+'-relaxed.pdb', \"w+\") as file:\n",
    "                    file.write(relaxed_text)\n",
    "\n",
    "    return CDR_rmsds_not_relaxed, decoy_diversities, order_of_pdbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 42min 28s, sys: 1min 26s, total: 1h 43min 54s\n",
      "Wall time: 3min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cdr_rmsds, decoy_diversities, pdb_ids = produce_full_structures_of_val_set(val_dataloader, model, outdir='test', relax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0.9121501445770264,\n",
       "   0.8906557559967041,\n",
       "   2.2079901695251465,\n",
       "   0.4420602023601532,\n",
       "   0.4020904302597046,\n",
       "   0.46330466866493225]],\n",
       " ['5hdq'],\n",
       " [[0.4799493789672852,\n",
       "   0.6126280784606933,\n",
       "   1.4202484130859374,\n",
       "   0.8075618743896484,\n",
       "   0.40671415328979493,\n",
       "   0.526338529586792]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdr_rmsds, pdb_ids, decoy_diversities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in val_dataloader:\n",
    "\n",
    "    coordinates, geomout, node_feature, mask, id = data['geomins'].float().to(device), data['geomouts'].float().to(device), data['encodings'].float().to(device), data['mask'].float().to(device), data['ids']\n",
    "id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ABDB import database as db\n",
    "from ABDB.AbPDB import AntibodyParser\n",
    "import numpy as np\n",
    "import Bio.PDB\n",
    "parser = AntibodyParser(PERMISSIVE=True, QUIET=True)\n",
    "parser.set_numbering_scheme(\"imgt\")\n",
    "db.set_numbering_scheme(\"imgt\")\n",
    "backbone = [\"CA\",\"C\",\"N\", \"CB\"]\n",
    "\n",
    "def CDR_rmsds(pdb, file, fab_n = 0, chains = [\"H\", \"L\"], decoy_chains = [\"H\", \"L\"]):\n",
    "    fab = db.fetch(pdb).fabs[fab_n]\n",
    "    rmsds = {}\n",
    "    for h_or_l in chains:\n",
    "        #Truth load\n",
    "        chain = db.db_summary[pdb][\"fabs\"][fab_n][h_or_l+\"chain\"]\n",
    "        truth = fab.get_structure()[chain]\n",
    "        #Decoy load\n",
    "        decoy = parser.get_antibody_structure(pdb+\"_model\", file)[0][{\"H\":decoy_chains[0], \"L\":decoy_chains[1]}[h_or_l]]\n",
    "        #Numbering\n",
    "        numb = [(\" \", *x) for x in fab.get_numbering()[h_or_l]][2:-2]\n",
    "        #Get residues to align\n",
    "        truth_res = [truth[x] for x in numb if (x in decoy) and (x in truth)]\n",
    "        decoy_res = [decoy[x] for x in numb if (x in decoy) and (x in truth)]\n",
    "        #Get atoms to align\n",
    "        fixed = []\n",
    "        moved = []\n",
    "        for i in range(len(decoy_res)):\n",
    "            fixed += [truth_res[i][atom] for atom in backbone if (atom in decoy_res[i]) and (atom in truth_res[i])]\n",
    "            moved += [decoy_res[i][atom] for atom in backbone if (atom in decoy_res[i]) and (atom in truth_res[i])]\n",
    "        #Calculate superimposer and move decoy\n",
    "        imposer = Bio.PDB.Superimposer()\n",
    "        imposer.set_atoms(fixed, moved)\n",
    "        imposer.apply(decoy.get_atoms())\n",
    "        rmsds[h_or_l] = imposer.rms\n",
    "        # Find CDR definitions\n",
    "        loop_definitions = {x[3:]:[(\" \", *y[0]) for y in fab.get_CDR_sequences(definition=\"imgt\")[x]]  for x in fab.get_CDR_sequences(definition=\"imgt\")}\n",
    "        # Calculate RMSD for each CDR\n",
    "        for CDR in loop_definitions:\n",
    "            if CDR[0] == h_or_l:\n",
    "                true_loop = []\n",
    "                decoy_loop = []\n",
    "                for res in loop_definitions[CDR]:\n",
    "                    if (res in truth) and (res in decoy):\n",
    "                        true_loop += [truth[res][x].get_coord() for x in backbone if (x in decoy[res]) and (x in truth[res])]\n",
    "                        decoy_loop+= [decoy[res][x].get_coord() for x in backbone if (x in decoy[res]) and (x in truth[res])]\n",
    "                #Calculate RMSD\n",
    "                rmsds[CDR] = np.sqrt(np.mean(3*(np.array(true_loop) - np.array(decoy_loop))**2))\n",
    "                \n",
    "    # Calculate RMSD for framework\n",
    "    ignore = sum([loop_definitions[x] for x in loop_definitions if x[0] == h_or_l], [])\n",
    "    frame_def = [x for x in numb if x not in ignore]\n",
    "    \n",
    "    true_frame, decoy_frame = [], []\n",
    "    for res in frame_def:\n",
    "        if (res in truth) and (res in decoy):\n",
    "            true_frame += [truth[res][x].get_coord() for x in backbone if (x in decoy[res]) and (x in truth[res])]\n",
    "            decoy_frame+= [decoy[res][x].get_coord() for x in backbone if (x in decoy[res]) and (x in truth[res])]\n",
    "    rmsds[h_or_l] = np.sqrt(np.mean(3*(np.array(true_frame) - np.array(decoy_frame))**2))\n",
    "                \n",
    "    return rmsds"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f5cb82b301b87eef88325f480de257324ba8b611cc1a51609875e0120daba8a9"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
