{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabian/miniconda3/envs/auto-db-pipeline/lib/python3.9/site-packages/Bio/SubsMat/__init__.py:126: BiopythonDeprecationWarning: Bio.SubsMat has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.substitution_matrices as a replacement, and contact the Biopython developers if you still need the Bio.SubsMat module.\n",
      "  warnings.warn(\n",
      "Database path /Volumes/LaCie/sabdab-sabpred/data/ABDB was not found.\n",
      "Warning: ABDB file system was not found. Database access not available\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ')' does not match opening parenthesis '{' on line 116 (training.py, line 118)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/Users/fabian/miniconda3/envs/auto-db-pipeline/lib/python3.9/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3457\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"/var/folders/8x/40q8fgwd2wg9ptnzw_b8cl480000gn/T/ipykernel_1099/3905329527.py\"\u001b[0m, line \u001b[1;32m10\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    from retrain_ablooper import *\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/fabian/Desktop/Antibody Project/ABlooper/retrain_ablooper/__init__.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from retrain_ablooper.training import *\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/fabian/Desktop/Antibody Project/ABlooper/retrain_ablooper/training.py\"\u001b[0;36m, line \u001b[0;32m118\u001b[0m\n\u001b[0;31m    'cdr_rmsd': cdr_rmsds)}\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m closing parenthesis ')' does not match opening parenthesis '{' on line 116\n"
     ]
    }
   ],
   "source": [
    "from ABDB import database as db\n",
    "import numpy as np\n",
    "from rich.progress import track\n",
    "import copy\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from einops import rearrange\n",
    "import json\n",
    "import pandas as pd\n",
    "from retrain_ablooper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data preparation\n",
    "**1.1 Get data from SAbDab**\n",
    "\n",
    "Extract CDR sequencs and coordinate of backbone atoms from antibodies in SAbDab. This steps takes approximately 2 hrs, thus the output is saved in .npy file. Download all FABs from SAbDab and extract data about CDR and anchor sequences and backbone coordinates. Data is saved in a .npy file.\n",
    "\n",
    "The set used for testing the model is the Rosetta antibody dataset. The pdb ids of these are indicated in './train_data/dataset.csv' with 'RAB' in the set column. The test set is loaded seperately from the other structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pdb ids of test set\n",
    "all_ids = pd.read_csv('./train_data/datasets.csv')\n",
    "test_ids = all_ids[all_ids['Set'] == 'RAB']\n",
    "test_ids = test_ids.PDB_ID.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5721, 5770, 49)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use imgt numbering\n",
    "db.set_numbering_scheme(\"imgt\")\n",
    "db.set_region_definition(\"imgt\")\n",
    "\n",
    "# list of all pdb ids in SAbDab\n",
    "all_pdbs_in_sabdab = list(db.db_summary.keys())\n",
    "train_val_set = set(all_pdbs_in_sabdab) - set(test_ids)\n",
    "len(train_val_set), len(all_pdbs_in_sabdab), len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Load data from SAbDab <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\"> 87%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:02</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Load data from SAbDab \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━\u001b[0m \u001b[35m 87%\u001b[0m \u001b[36m0:00:02\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load test set\n",
    "CDR_seqs_test, CDR_BB_coords_test = get_sabdab_fabs(test_ids)\n",
    "\n",
    "with open('train_data/CDR_BB_coords_test.npy', 'wb') as outfile:\n",
    "    np.save(outfile, CDR_BB_coords_test)\n",
    "\n",
    "with open('train_data/CDR_seqs_test.npy', 'wb') as outfile:\n",
    "    np.save(outfile, CDR_seqs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_sabdab_fabs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8x/40q8fgwd2wg9ptnzw_b8cl480000gn/T/ipykernel_51920/2542225449.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load training and validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mCDR_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCDR_BB_coords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sabdab_fabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_val_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_data/CDR_BB_coords.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCDR_BB_coords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_sabdab_fabs' is not defined"
     ]
    }
   ],
   "source": [
    "# load training and validation set\n",
    "CDR_seqs, CDR_BB_coords = get_sabdab_fabs(train_val_set)\n",
    "\n",
    "with open('train_data/CDR_BB_coords.npy', 'wb') as outfile:\n",
    "    np.save(outfile, CDR_BB_coords)\n",
    "\n",
    "with open('train_data/CDR_seqs.npy', 'wb') as outfile:\n",
    "    np.save(outfile, CDR_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_data/CDR_BB_coords.npy', 'rb') as infile:\n",
    "    CDR_BB_coords = np.load(infile, allow_pickle=True)\n",
    "\n",
    "with open('train_data/CDR_seqs.npy', 'rb') as infile:\n",
    "    CDR_seqs = np.load(infile, allow_pickle=True)\n",
    "\n",
    "with open('train_data/CDR_BB_coords_test.npy', 'rb') as infile:\n",
    "    CDR_BB_coords_test = np.load(infile, allow_pickle=True)\n",
    "\n",
    "with open('train_data/CDR_seqs_test.npy', 'rb') as infile:\n",
    "    CDR_seqs_test = np.load(infile, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 Format data to model inputs**\n",
    "\n",
    "Data loaded from SAbDab is reformated to model inputs and the training outputs. \n",
    "\n",
    "Each backbone atom corresponds to one node in the graph. The atoms are encoded into a vector with 41 elements (one-hot encoding of amino acid residue, one-hot encoding of atom type, one-hot encoding of CDR loop, positional encoding within loop).\n",
    "\n",
    "The input coordinates of each backbone atoms are processed as follows. Anchor residues keep their original position, the CDR residues are spaced equally on a straigt line between the two anchors.\n",
    "\n",
    "The training output coordinates correspond to the backbone coordinates from the crystal structure formated identically to the input coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch settings\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_dtype(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Preparing model inputs <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Preparing model inputs \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f75f28a1033410bb11b8bb8803c08c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "geomins, node_encodings = prepare_model_inputs(CDR_seqs, CDR_BB_coords)\n",
    "geomouts = prepare_model_output(CDR_BB_coords)\n",
    "\n",
    "geomins_test, node_encodings_test = prepare_model_inputs(CDR_seqs_test, CDR_BB_coords_test)\n",
    "geomouts_test = prepare_model_output(CDR_BB_coords_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CDR loops retrieve from SAbDab differ in numbers of residues. This leads to the node feature and coordinate tensors being of different sizes. When the model is trained in batches it cannot handle different formats of input tensors. \n",
    "\n",
    "To avoid this issues a mask is created. The mask is a vector of length 504 (which is the number of atoms in the longest Fab) and contains n_atoms * 1s and is filed up with 0s to 504. The coordinates and input node features are also padded to a size of 504 with 0s.\n",
    "\n",
    "Format the data extracted in the previous step into the input tensors.\n",
    "\n",
    "1. node_encodings: matrix of size 504 * 41, encoding node features\n",
    "2. geomins: matrix of size 504 * 3, encoding the input coordinates of the CDR backbone residues (all residues equally spaced on a straight line between anchors)\n",
    "3. geomouts: matrix of size 504 * 3, encoding the original coordinates of the CDR backbone residues\n",
    "\n",
    "504 = number of atoms in longest FAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates mask for each fab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = create_mask(node_encodings)\n",
    "masks_test = create_mask(node_encodings_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pads the node features and geoms to a length of 504"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad all data\n",
    "node_encodings = pad_list_of_tensors(node_encodings)\n",
    "geomins = pad_list_of_tensors(geomins)\n",
    "geomouts = pad_list_of_tensors(geomouts)\n",
    "node_encodings_test = pad_list_of_tensors(node_encodings_test)\n",
    "geomins_test = pad_list_of_tensors(geomins_test)\n",
    "geomouts_test = pad_list_of_tensors(geomouts_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the all data into a single array, where each element corresponds to a fab. Within an element the data is saved in a dictionary with keys: 'encodings', 'geomins', 'geomouts' and 'mask'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8071, 46)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = concatenate_data(node_encodings, geomins, geomouts, masks)\n",
    "test = concatenate_data(node_encodings_test, geomins_test, geomouts_test, masks_test)\n",
    "len(data), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3 Prepare data for training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7971, 100, 46)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split in train and validation sets\n",
    "train, validation = train_test_split(data, test_size=100, random_state=42)\n",
    "\n",
    "len(train), len(validation), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_dataloader = torch.utils.data.DataLoader(train, \n",
    "                                               batch_size=batch_size,   # Batch size\n",
    "                                               num_workers=1,           # Number of cpu's allocated to load the data (recommended is 4/GPU)\n",
    "                                               shuffle=True,            # Whether to randomly shuffle data\n",
    "                                               pin_memory=True,         # Enables faster data transfer to CUDA-enabled GPUs (page-locked memory)\n",
    "                                               )\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(validation, \n",
    "                                             batch_size=batch_size,\n",
    "                                             num_workers=1,\n",
    "                                             shuffle=True,\n",
    "                                             pin_memory=True,\n",
    "                                             )\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test, \n",
    "                                              batch_size=batch_size,\n",
    "                                              num_workers=1,\n",
    "                                              shuffle=True,\n",
    "                                              pin_memory=True,\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Train model\n",
    "**2.1 Run training code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8x/40q8fgwd2wg9ptnzw_b8cl480000gn/T/ipykernel_57300/3948394701.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Step to actually train the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Antibody Project/ABlooper/retrain_ablooper/training.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimiser, train_dataloader, val_dataloader, n_epochs, patience, decoys)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" Train |  Val \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcdr_rmsd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoys\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Run one epoch and get train and validation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m                                                    \u001b[0;31m# Store train and validation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Antibody Project/ABlooper/retrain_ablooper/training.py\u001b[0m in \u001b[0;36mmask_run_epoch\u001b[0;34m(model, optim, train_dataloader, val_dataloader, decoys, grad_clip)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mepoch_train_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m                         \u001b[0;31m# Store value of loss function for training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                                                \u001b[0;31m# Calculate loss gradients (pytorch handles this in the background)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_clip\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Optional: Clip the norm of the gradient (It stops the optimiser from doing very large updates at once)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                                                   \u001b[0;31m# Update model weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/auto-db-pipeline/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/auto-db-pipeline/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initialise model\n",
    "model = MaskDecoyGen().to(device = device).float()\n",
    "\n",
    "# set optimiser\n",
    "optimiser = torch.optim.RAdam(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "\n",
    "# Step to actually train the network\n",
    "train_losses, val_losses = train_model(model, optimiser, train_dataloader, val_dataloader, n_epochs=5000, patience=150, decoys=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Analyse trainig**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model trained on 16-04, 1 decoy, optimiser: RAdam, 268 epochs, batch size = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(loss_text, **kwargs):\n",
    "    if kwargs['loss'] == 'train':\n",
    "        which = 0\n",
    "    elif kwargs['loss'] == 'val':\n",
    "        which = 1\n",
    "    \n",
    "    losses = []\n",
    "    loss_text = loss_text[1:] # remove header\n",
    "    for i in range(len(loss_text)):\n",
    "        losses.append(float(loss_text[i].strip().split('|')[which]))\n",
    "    \n",
    "    return np.asarray(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('losses_1604.out', 'r') as f:\n",
    "    text = f.readlines()\n",
    "loss_text = text[4:]\n",
    "\n",
    "train_loss = get_loss(loss_text, loss='train')\n",
    "val_loss = get_loss(loss_text, loss='val')\n",
    "\n",
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(val_loss, '--', label='val')\n",
    "plt.ylim((1.2,2))\n",
    "plt.legend()\n",
    "plt.ylabel('RMSD')\n",
    "plt.xlabel('epoch')\n",
    "plt.savefig('figures/train_val_losses-1604.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rmsd for each CDR on val set with best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialise model\n",
    "model = MaskDecoyGen().to(device = device).float()\n",
    "model.load_state_dict(torch.load(\"best_model\", map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdr_rmsd_val_set(decoys, val_dataloader):\n",
    "    '''\n",
    "    Calculates the mean rmsd per cdr for a validation set\n",
    "    '''\n",
    "    CDRs = ['H1', 'H2', 'H3', 'L1', 'L2', 'L3']\n",
    "    cdr_rmsds = torch.zeros(decoys, 100, len(CDRs))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval() \n",
    "\n",
    "        for i, data in enumerate(val_dataloader):\n",
    "            node_features = data['encodings']\n",
    "            coordinates = data['geomins']\n",
    "            out_coordinates = data['geomouts']\n",
    "            mask = data['mask']\n",
    "\n",
    "            pred = model(node_features, coordinates, mask)\n",
    "\n",
    "            cdr_rmsds[:,i,:] = rmsd_per_cdr(pred, node_features, out_coordinates, CDRs, decoys)\n",
    "\n",
    "        return cdr_rmsds.mean(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr_rmsd = cdr_rmsd_val_set(1, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1, H2, H3, L1, L2, L3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.2416, 1.2083, 3.2649, 1.2498, 0.6153, 1.3835]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('H1, H2, H3, L1, L2, L3')\n",
    "cdr_rmsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Use Pytorch lighting for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning\n",
    "from pytorch_lightning.loggers.neptune import NeptuneLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "ourlogger = NeptuneLogger(api_key=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIyMGI0ZTUzYy0zMTBkLTRjMWMtODhjNS0wNTJmNjA1MzhmOGMifQ==\",\n",
    "              project=\"fspoendlin/ABlooper\",\n",
    "              name=\"Fabian\",\n",
    "              log_model_checkpoints=False,\n",
    "              )\n",
    "\n",
    "trainer = pytorch_lightning.Trainer(\n",
    "    accelerator=\"auto\",  # 'cpu' or 'gpu'\n",
    "    max_epochs=5000,\n",
    "    check_val_every_n_epoch=1,\n",
    "    accumulate_grad_batches=None,\n",
    "    gradient_clip_val=1.0,\n",
    "    logger=ourlogger,\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | egnnmodel | MaskDecoyGen | 662 K \n",
      "-------------------------------------------\n",
      "662 K     Trainable params\n",
      "0         Non-trainable params\n",
      "662 K     Total params\n",
      "2.649     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabian/miniconda3/envs/auto-db-pipeline/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:486: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/Users/fabian/miniconda3/envs/auto-db-pipeline/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model = pl_EGNNModel()\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b68f9eedec4825490a01d6907fa8139c5284fcb4395b458f0f41fe7d228fceae"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('ab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
