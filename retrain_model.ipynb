{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabian/miniconda3/envs/auto-db-pipeline/lib/python3.9/site-packages/Bio/SubsMat/__init__.py:126: BiopythonDeprecationWarning: Bio.SubsMat has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.substitution_matrices as a replacement, and contact the Biopython developers if you still need the Bio.SubsMat module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from ABDB import database as db\n",
    "import numpy as np\n",
    "from rich.progress import track\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from einops import rearrange\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data preparation\n",
    "**1.1 Get data from SAbDab**\n",
    "\n",
    "Extract CDR sequencs and coordinate of backbone atoms from antibodies in SAbDab. This steps takes approximately 2 hrs, thus the output is saved in .npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries to convert one letter, three letter and numerical amino acid codes\n",
    "aa1 = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "aa3 = [\"ALA\", \"CYS\", \"ASP\", \"GLU\", \"PHE\", \"GLY\", \"HIS\", \"ILE\", \"LYS\", \"LEU\", \"MET\", \"ASN\", \"PRO\", \"GLN\", \"ARG\", \"SER\",\n",
    "       \"THR\", \"VAL\", \"TRP\", \"TYR\", ]\n",
    "\n",
    "short2long = {}\n",
    "long2short = {}\n",
    "short2num = {}\n",
    "\n",
    "for ind in range(0, 20):\n",
    "    long2short[aa3[ind]] = aa1[ind]\n",
    "    short2long[aa1[ind]] = aa3[ind]\n",
    "    short2num[aa1[ind]] = ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to filter entries in SAbDAb\n",
    "\n",
    "def filter_abs(pdb_list):\n",
    "    '''\n",
    "    Filter a list of PDB ids obtained from SAbDab and removes FABS where one of the chains is missing or where\n",
    "    heavy and light chains have the same name.\n",
    "    '''\n",
    "    filtered_list = []\n",
    "    i = 0\n",
    "    \n",
    "    for pdb in track(pdb_list, description='Filter FABs'):\n",
    "        i += 1\n",
    "        fab = db.fetch(pdb).fabs[0]\n",
    "\n",
    "        if fab.VH == fab.VL:\n",
    "            continue\n",
    "        elif fab.VH == 'NA' or fab.VL == 'NA':\n",
    "            continue\n",
    "        else:\n",
    "            filtered_list.append(pdb)\n",
    "\n",
    "    return filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to extract and format relevant data from a SAbDab FAB. Given a FAB two dictionaries are returned for CDR and anchor \n",
    "# sequences and thier backbone coordinates\n",
    "\n",
    "def split_structure_in_regions(fab):\n",
    "    '''\n",
    "    Split FAB into regions.\n",
    "\n",
    "    Takes FAB as input an returns a dictionary with keys: regions, values: residues in region\n",
    "    regions = ['fwh1', 'cdrh1', 'fwh2', 'cdrh2', 'fwh3', 'cdrh3', 'fwh4', 'fwl1', 'cdrl1', 'fwl2', 'cdrl2', 'fwl3', 'cdrl3', 'fwl4']\n",
    "    '''\n",
    "    ab_regions = dict()\n",
    "    struc = fab.get_structure()\n",
    "\n",
    "    for chain in [fab.VH, fab.VL]:\n",
    "\n",
    "        # Chian.get_residues() is a generator that loops through residue\n",
    "        for residue in struc[chain].get_residues():\n",
    "\n",
    "            # residue.region indicates in which cdr or framework region the residue is\n",
    "            if residue.region in ab_regions:\n",
    "                ab_regions[residue.region].append(residue)\n",
    "            else:\n",
    "                ab_regions[residue.region] = [residue]\n",
    "\n",
    "    return ab_regions\n",
    "\n",
    "def get_slice(ab_regions, CDR):\n",
    "    '''\n",
    "    Returns a slice of residues containing a CDR plus two anchor residues on each side,\n",
    "    given a FAB split in to regions and a spefied CDR.\n",
    "    '''\n",
    "    chain = CDR[0].lower()\n",
    "    loop = CDR[1]\n",
    "\n",
    "    slice = ab_regions['fw' + chain + loop][-2:]\n",
    "    slice += ab_regions['cdr' + chain + loop]\n",
    "    slice += ab_regions['fw' + chain + str(int(loop) + 1 )][:2]\n",
    "\n",
    "    return slice\n",
    "\n",
    "def cdr_anchor_seq(ab_regions, CDR):\n",
    "    '''\n",
    "    Retruns sequence of a CDR plus two anchors on each side,\n",
    "    given a FAB split in to regions and a spefied CDR.\n",
    "    '''\n",
    "    slice = get_slice(ab_regions, CDR)\n",
    "    CDR_seq = []\n",
    "\n",
    "    for res in slice:\n",
    "        CDR_seq.append(long2short[res.resname])\n",
    "\n",
    "    return CDR_seq\n",
    "\n",
    "def cdr_anchor_BB_coord(ab_regions, CDR):\n",
    "    '''\n",
    "    Returns coordinates of backbone atoms of a CDR plus two anchors on each side,\n",
    "    given a FAB split in to regions and a spefied CDR.\n",
    "    '''\n",
    "    slice = get_slice(ab_regions, CDR)\n",
    "    CDR_BB_coord = np.zeros((len(slice), 4, 3))\n",
    "    BB_atoms = [\"CA\", \"C\", \"N\", \"CB\"]\n",
    "\n",
    "    for i in range(len(slice)):\n",
    "        res = slice[i]\n",
    "        for j in range(len(BB_atoms)):\n",
    "            atom = BB_atoms[j]\n",
    "\n",
    "            # if residue is glycine use CA coordinates for CB\n",
    "            if res.resname == 'GLY' and atom == 'CB':\n",
    "                atom = \"CA\"\n",
    "                \n",
    "            coord = res[atom].coord\n",
    "\n",
    "            CDR_BB_coord[i, j, :] = coord\n",
    "    \n",
    "    return CDR_BB_coord\n",
    "\n",
    "def get_cdr_anchor_seqs(ab_regions, CDRs = [\"H1\", \"H2\", \"H3\", \"L1\", \"L2\", \"L3\"]):\n",
    "    '''\n",
    "    Get sequences of all CDRs in a FAB.\n",
    "\n",
    "    Returns a dictionary with keys: CDRs, values: CDR + anchor sequence\n",
    "    '''\n",
    "    CDR_seqs = dict()\n",
    "\n",
    "    for CDR in CDRs:\n",
    "        CDR_seqs[CDR] = cdr_anchor_seq(ab_regions, CDR)\n",
    "   \n",
    "    return CDR_seqs\n",
    "\n",
    "def get_cdr_anchor_BB_coords(cdr_residues, CDRs = [\"H1\", \"H2\", \"H3\", \"L1\", \"L2\", \"L3\"]):\n",
    "    '''\n",
    "    Get backbone coordinates of all CDRs in a FAB.\n",
    "    \n",
    "    Returns a dictionary with keys: CDRs, values: CDR + anchor backbone coordinates\n",
    "    '''\n",
    "    CDR_BB_coords = dict()\n",
    "\n",
    "    for CDR in CDRs:\n",
    "        CDR_BB_coords[CDR] = cdr_anchor_BB_coord(cdr_residues, CDR)\n",
    "   \n",
    "    return CDR_BB_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to retrieve PDB ids from SAbDab and runs functions in above cells for each individual FAB.\n",
    "\n",
    "def get_sabdab_fabs(pdb_list):\n",
    "    '''\n",
    "    Get fabs from sabdab given a list of pdbs, extracts CDR sequences and coordinates and formats the data for the next steps.\n",
    "\n",
    "    returns CDR_seqs: list of dictionaries,\n",
    "                      each dictionary contains data of one FAB, keys: CDR, value: CDR sequence\n",
    "    returns CDR_BB_coords: list of dictionaries,\n",
    "                           each dictionary contains data of one FAB, keys: CDR, value: CDR backbone coordinates\n",
    "    '''\n",
    "    pdb_list = filter_abs(pdb_list)\n",
    "\n",
    "    CDR_seqs = list()\n",
    "    CDR_BB_coords = list()\n",
    "\n",
    "    for pdb_id in track(pdb_list, description='Load data from SAbDab'):\n",
    "        pdb = db.fetch(pdb_id)\n",
    "        for fab in pdb.fabs:\n",
    "            try: # some fab have errors and throw exceptions, ignore these\n",
    "                ab_regions = split_structure_in_regions(fab)\n",
    "                cdr_seqs = get_cdr_anchor_seqs(ab_regions)\n",
    "                cdr_BB_coords = get_cdr_anchor_BB_coords(ab_regions)\n",
    "\n",
    "                CDR_seqs.append(cdr_seqs)\n",
    "                CDR_BB_coords.append(cdr_BB_coords)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    return CDR_seqs, CDR_BB_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code that runs the above functions to download all FABs from SAbDab and extract data about CDR and anchor sequences and backbone coordinates. Data is saved in a .npy file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Filter FABs <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\"> 11%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:01:17</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Filter FABs \u001b[38;2;249;38;114m━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 11%\u001b[0m \u001b[36m0:01:17\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8x/40q8fgwd2wg9ptnzw_b8cl480000gn/T/ipykernel_927/1331454936.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mall_pdbs_in_sabdab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mCDR_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCDR_BB_coords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sabdab_fabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_pdbs_in_sabdab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/8x/40q8fgwd2wg9ptnzw_b8cl480000gn/T/ipykernel_927/289127317.py\u001b[0m in \u001b[0;36mget_sabdab_fabs\u001b[0;34m(pdb_list)\u001b[0m\n\u001b[1;32m     10\u001b[0m                            \u001b[0meach\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mof\u001b[0m \u001b[0mone\u001b[0m \u001b[0mFAB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCDR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCDR\u001b[0m \u001b[0mbackbone\u001b[0m \u001b[0mcoordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     '''\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mpdb_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_abs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdb_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mCDR_seqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/8x/40q8fgwd2wg9ptnzw_b8cl480000gn/T/ipykernel_927/1842118633.py\u001b[0m in \u001b[0;36mfilter_abs\u001b[0;34m(pdb_list)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpdb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdb_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Filter FABs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mfab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfabs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVH\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/auto-db-pipeline/lib/python3.9/site-packages/ABDB/Database_interface.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, pdb)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;31m# This makes loadall feasible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mpdb_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_headerpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_headerpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0mpdb_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0mpdb_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_annotationpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_annotationpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mpdb_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_sequencepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequencepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/auto-db-pipeline/lib/python3.9/site-packages/ABDB/Database_interface.py\u001b[0m in \u001b[0;36m_get_filepath\u001b[0;34m(self, pdb)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \"\"\"\n\u001b[1;32m    548\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"entries\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"structure\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%s.pdb\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/auto-db-pipeline/lib/python3.9/genericpath.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# use imgt numbering\n",
    "db.set_numbering_scheme(\"imgt\")\n",
    "db.set_region_definition(\"imgt\")\n",
    "\n",
    "# list of all pdb ids in SAbDab\n",
    "all_pdbs_in_sabdab = list(db.db_summary.keys())\n",
    "\n",
    "CDR_seqs, CDR_BB_coords = get_sabdab_fabs(all_pdbs_in_sabdab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('train_data/CDR_BB_coords.npy', 'wb') as outfile:\n",
    "#    np.save(outfile, CDR_BB_coords)\n",
    "\n",
    "# with open('train_data/CDR_seqs.npy', 'wb') as outfile:\n",
    "#    np.save(outfile, CDR_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_data/CDR_BB_coords.npy', 'rb') as infile:\n",
    "    CDR_BB_coords = np.load(infile, allow_pickle=True)\n",
    "\n",
    "with open('train_data/CDR_seqs.npy', 'rb') as infile:\n",
    "    CDR_seqs = np.load(infile, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 Format data to model inputs**\n",
    "\n",
    "Data loaded from SAbDab is reformated to model inputs and the training outputs. \n",
    "\n",
    "Each backbone atom corresponds to one node in the graph. The atoms are encoded into a vector with 41 elements (one-hot encoding of amino acid residue, one-hot encoding of atom type, one-hot encoding of CDR loop, positional encoding within loop).\n",
    "\n",
    "The input coordinates of each backbone atoms are processed as follows. Anchor residues keep their original position, the CDR residues are spaced equally on a straigt line between the two anchors.\n",
    "\n",
    "The training output coordinates correspond to the backbone coordinates from the crystal structure formated identically to the input coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions that convert data extracted from SAbDab to model input\n",
    "\n",
    "def encode(x, classes):\n",
    "    '''\n",
    "    One hot encodes a scalar x into a vector of length classes.\n",
    "    This is the function used for Sequence encoding.\n",
    "    '''\n",
    "    one_hot = np.zeros(classes)\n",
    "    one_hot[x] = 1\n",
    "\n",
    "    return one_hot\n",
    "\n",
    "def one_hot(num_list, classes=20):\n",
    "    '''\n",
    "    One hot encodes a 1D vector x.\n",
    "    This is the function used for Sequence encoding.\n",
    "    '''\n",
    "    end_shape = (len(num_list), classes)\n",
    "    finish = np.zeros(end_shape)\n",
    "    for i in range(end_shape[0]):\n",
    "        finish[i] = encode(num_list[i], classes)\n",
    "\n",
    "    return finish\n",
    "\n",
    "def which_loop(loop_seq, cdr):\n",
    "    '''\n",
    "    Adds a one-hot encoded vector to each node describing which CDR it belongs to.\n",
    "    '''\n",
    "    CDRs = [\"H1\", \"H2\", \"H3\", \"L1\", \"L2\", \"L3\", \"Anchor\"]\n",
    "    loop = np.zeros((len(loop_seq), len(CDRs)))\n",
    "    loop[:, -1] = 1\n",
    "    loop[2:-2] = np.array([1.0 if cdr == x else 0.0 for x in (CDRs)])[None].repeat(len(loop_seq) - 4, axis=0)\n",
    "\n",
    "    return loop\n",
    "\n",
    "def positional_encoding(sequence, n=5):\n",
    "    '''\n",
    "    Gives the network information on how close each resdiue is to the anchors\n",
    "    '''\n",
    "    encs = []\n",
    "    L = len(sequence)\n",
    "    for i in range(n):\n",
    "        encs.append(np.cos((2 ** i) * np.pi * np.arange(L) / L))\n",
    "        encs.append(np.sin((2 ** i) * np.pi * np.arange(L) / L))\n",
    "\n",
    "    return np.array(encs).transpose()\n",
    "\n",
    "def res_to_atom(res_encoding, n_atoms=4):\n",
    "    '''\n",
    "    Adds a one-hot encoded vector to each node describing what atom type it is.\n",
    "    '''\n",
    "    out_shape = (res_encoding.shape[0], n_atoms, 41)\n",
    "    atom_encoding = np.zeros(out_shape)\n",
    "\n",
    "    for i in range(len(res_encoding)):\n",
    "        for j in range(n_atoms):\n",
    "            atom_encoding[i, j, 0:37] = res_encoding[i]\n",
    "            # add one-hot encoding for atom type\n",
    "            atom_encoding[i, j, 37:] = one_hot([j], classes=n_atoms) \n",
    "\n",
    "    return atom_encoding\n",
    "\n",
    "def prepare_input_loop(CDR_coord, CDR_seq, CDR):\n",
    "    '''\n",
    "    Generates input features to be fed into the network for a single CDR\n",
    "    '''\n",
    "    CDR_input_coord = copy.deepcopy(CDR_coord)\n",
    "    # put CDR residues equally spaced on straight line between anchor residues \n",
    "    CDR_input_coord[1:-1] = np.linspace(CDR_coord[1], CDR_coord[-2], len(CDR_coord) - 2)\n",
    "    # CDR_input_coord = rearrange(torch.tensor(CDR_input_coords), \"i a d -> () (i a) d\").float()\n",
    "\n",
    "    one_hot_encoding = one_hot(np.array([short2num[amino] for amino in CDR_seq]))\n",
    "    loop = which_loop(CDR_seq, CDR)\n",
    "    positional = positional_encoding(CDR_seq)\n",
    "    res_encoding = np.concatenate([one_hot_encoding, positional, loop], axis=1)\n",
    "    atom_encoding = res_to_atom(res_encoding)\n",
    "\n",
    "    # encoding = res_to_atom(torch.tensor(np.concatenate([one_hot_encoding, positional, loop], axis=1)).float())\n",
    "    # encoding = rearrange(encoding, \"i a d -> () (i a) d\")\n",
    "\n",
    "    return CDR_input_coord, atom_encoding\n",
    "\n",
    "def prepare_model_input(CDR_seq, CDR_BB_coord):\n",
    "    '''\n",
    "    Prepares model inputs for a single FAB\n",
    "    '''\n",
    "    encodings = []\n",
    "    geomins = []\n",
    "    \n",
    "    for CDR in CDR_BB_coord:\n",
    "        geom, encode = prepare_input_loop(CDR_BB_coord[CDR], CDR_seq[CDR], CDR)\n",
    "        encodings.append(encode)\n",
    "        geomins.append(geom)\n",
    "\n",
    "    # concatenate encodings and geoms into single array\n",
    "    encodings = np.concatenate(encodings, axis=0)\n",
    "    geomins = np.concatenate(geomins, axis=0)\n",
    "    # format to tensor\n",
    "    encodings = torch.from_numpy(encodings)\n",
    "    geomins = torch.from_numpy(geomins)\n",
    "    # rearrange tensors that atoms in one residue are nolonger grouped\n",
    "    encodings = rearrange(encodings, \"i a d -> (i a) d\")\n",
    "    geomins = rearrange(geomins, \"i a d -> (i a) d\")\n",
    "\n",
    "    return geomins, encodings\n",
    "\n",
    "def prepare_model_inputs(CDR_seqs, CDR_BB_coords):\n",
    "    '''\n",
    "    Prepares model inputs for a list of FABs\n",
    "    '''\n",
    "    encodings = []\n",
    "    geomins = []\n",
    "\n",
    "    for i in track(range(len(CDR_seqs)), description='Preparing model inputs'):\n",
    "        geom, encode = prepare_model_input(CDR_seqs[i], CDR_BB_coords[i])\n",
    "        encodings.append(encode)\n",
    "        geomins.append(geom)\n",
    "\n",
    "    return geomins, encodings\n",
    "\n",
    "def prepare_model_output(CDR_BB_coords):\n",
    "    '''\n",
    "    Prepares model outputs for training, formated identically to inputs\n",
    "    '''\n",
    "    geomouts = []\n",
    "    for CDR_BB_coord in track(CDR_BB_coords, description='Preparing model outputs'):\n",
    "        geomout = []\n",
    "        for _, coords in CDR_BB_coord.items():\n",
    "            geomout.append(coords)\n",
    "\n",
    "        # concatenate geoms into single array\n",
    "        geomout = np.concatenate(geomout, axis=0)\n",
    "        # format to tensor\n",
    "        geomout = torch.from_numpy(geomout)\n",
    "        # rearrange tensor\n",
    "        geomout = rearrange(geomout, \"i a d -> (i a) d\")\n",
    "\n",
    "        geomouts.append(geomout)\n",
    "    return geomouts\n",
    "\n",
    "def concatenate_data(encodings, geomins, geomouts, masks):\n",
    "    '''\n",
    "    Puts encodings, geomins and geomouts into a single array.\n",
    "    '''\n",
    "    data = []\n",
    "    for i in range(len(encodings)):\n",
    "        # potentially change list to dict\n",
    "        data.append({'encodings': encodings[i],\n",
    "                     'geomins': geomins[i],\n",
    "                     'geomouts': geomouts[i],\n",
    "                     'mask': masks[i]})\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CDR loops retrieve from SAbDab differ in numbers of residues. This leads to the node feature and coordinate tensors being of different sizes. When the model is trained in batches it cannot handle different formats of input tensors. \n",
    "\n",
    "To avoid this issues a mask is created. The mask is a vector of length 504 (which is the number of atoms in the longest Fab) and contains n_atoms * 1s and is filed up with 0s to 504. The coordinates and input node features are also padded to a size of 504 with 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat mask\n",
    "def create_mask(node_encoding, mask_lenght=504):\n",
    "    '''\n",
    "    Function that creates a mask of a certain length with 1s where there is an atom and filled up with 0s\n",
    "    '''\n",
    "    mask = torch.zeros((mask_lenght))\n",
    "    mask[:len(node_encoding)] = 1\n",
    "    return mask\n",
    "\n",
    "# padding\n",
    "def pad_data_for_batch(tensor, out_lenght=504):\n",
    "    '''\n",
    "    Pads all tensors with 0 to the same number of nodes\n",
    "    '''\n",
    "    ndim = tensor.shape[1]\n",
    "    outtensor = torch.zeros((out_lenght, ndim))\n",
    "    outtensor[:tensor.shape[0], :] = tensor\n",
    "    return outtensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format the data extracted in the previous step into the input tensors.\n",
    "\n",
    "1. node_encodings: matrix of size n_atoms * 41, encoding node features\n",
    "2. geomins: matrix of size n_atoms * 3, encoding the input coordinates of the CDR backbone residues (all residues equally spaced on a straight line between anchors)\n",
    "3. geomouts: matrix of size n_atoms * 3, encoding the original coordinates of the CDR backbone residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Preparing model outputs <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Preparing model outputs \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "geomins, node_encodings = prepare_model_inputs(CDR_seqs, CDR_BB_coords)\n",
    "geomouts = prepare_model_output(CDR_BB_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates mask for each fab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = []\n",
    "for node_encoding in node_encodings:\n",
    "    mask = create_mask(node_encoding)\n",
    "    masks.append(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pads the node features and geoms to a length of 504"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "geomins_padded = []\n",
    "geomouts_padded = []\n",
    "node_encodings_padded = []\n",
    "\n",
    "for i in range(len(geomins)):\n",
    "    geomins_padded.append(pad_data_for_batch(geomins[i]))\n",
    "    geomouts_padded.append(pad_data_for_batch(geomouts[i]))\n",
    "    node_encodings_padded.append(pad_data_for_batch(node_encodings[i]))\n",
    "\n",
    "geomins = geomins_padded\n",
    "geomouts = geomouts_padded\n",
    "node_encodings = node_encodings_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the all data into a single array, where each element corresponds to a fab. Within an element the data is saved in a dictionary with keys: 'encodings', 'geomins', 'geomouts' and 'mask'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8117"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = concatenate_data(node_encodings, geomins, geomouts, masks)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3 Prepare data for training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7967, 100, 50)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split 0.6, 0.2, 0.2 in train, test and validation sets\n",
    "train, test = train_test_split(data, test_size=50, random_state=42,)\n",
    "train, validation = train_test_split(train, test_size=100, random_state=42)\n",
    "\n",
    "len(train), len(validation), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataloader = torch.utils.data.DataLoader(train, \n",
    "                                               batch_size=batch_size,   # Batch size\n",
    "                                               num_workers=1,           # Number of cpu's allocated to load the data (recommended is 4/GPU)\n",
    "                                               shuffle=True,            # Whether to randomly shuffle data\n",
    "                                               pin_memory=True,         # Enables faster data transfer to CUDA-enabled GPUs (page-locked memory)\n",
    "                                               )\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(validation, \n",
    "                                             batch_size=batch_size,\n",
    "                                             num_workers=1,\n",
    "                                             shuffle=True,\n",
    "                                             pin_memory=True,\n",
    "                                             )\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test, \n",
    "                                              batch_size=batch_size,\n",
    "                                              num_workers=1,\n",
    "                                              shuffle=True,\n",
    "                                              pin_memory=True,\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implement the EGNN\n",
    "\n",
    "**2.1 EGNN basic implementation**\n",
    "\n",
    "This first implementation of the model does not use a mask. This cannot be trained in batches as the sizes of input tensors need to be identical within a batch. Also, this model should be used with the not padded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EGNN(torch.nn.Module):\n",
    "    '''\n",
    "    Singel layer of an EGNN.\n",
    "    '''\n",
    "    def __init__(self, node_dim, message_dim=32):\n",
    "        super().__init__()\n",
    "\n",
    "        edge_input_dim = (node_dim * 2) + 1\n",
    "\n",
    "        self.edge_mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(edge_input_dim, 2*edge_input_dim),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(2*edge_input_dim, message_dim),\n",
    "            torch.nn.SiLU()\n",
    "        )\n",
    "\n",
    "        self.node_mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(node_dim + message_dim, 2*node_dim),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(2*node_dim, node_dim),\n",
    "        )\n",
    "\n",
    "        self.coors_mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(message_dim, 2*message_dim),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(2*message_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, node_features, coordinates):                                                        # We pass in a mask that tells us what nodes to consider and which to ignore.\n",
    "        rel_coors = rearrange(coordinates, 'b i d -> b i () d') - rearrange(coordinates, 'b j d -> b () j d')  \n",
    "        rel_dist = (rel_coors ** 2).sum(dim=-1, keepdim=True)                                                  \n",
    "\n",
    "        feats_j = rearrange(node_features, 'b j d -> b () j d')      \n",
    "        feats_i = rearrange(node_features, 'b i d -> b i () d')\n",
    "        feats_i, feats_j = torch.broadcast_tensors(feats_i, feats_j)\n",
    "\n",
    "        edge_input = torch.cat((feats_i, feats_j, rel_dist), dim=-1)\n",
    "\n",
    "        m_ij = self.edge_mlp(edge_input)\n",
    "\n",
    "        coor_weights = self.coors_mlp(m_ij)                                                          # We multiply the predicted weight by the mask (masked residue pairs will have zero weight).\n",
    "        coor_weights = rearrange(coor_weights, 'b i j () -> b i j')\n",
    "\n",
    "        rel_coors_normed = rel_coors / rel_dist.clip(min = 1e-8)    \n",
    "\n",
    "        coors_out = coordinates + torch.einsum('b i j, b i j c -> b i c', coor_weights, rel_coors_normed)  \n",
    "\n",
    "        m_i = m_ij.sum(dim=-2)                                                                      # To average we divide over the length for each batch (length = sum(mask)).\n",
    "\n",
    "        node_mlp_input = torch.cat((node_features, m_i), dim=-1)\n",
    "        node_out = node_features + self.node_mlp(node_mlp_input)                            # We set the update for maked residues to zero. \n",
    "\n",
    "        return node_out, coors_out\n",
    "\n",
    "class EGNNModel(torch.nn.Module):\n",
    "    '''\n",
    "    4 EGNN layers joined into one Model\n",
    "    '''\n",
    "    def __init__(self, node_dim, layers=4, message_dim=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = torch.nn.ModuleList([EGNN(node_dim, message_dim = message_dim) for _ in range(layers)])   # Initialise as many EGNN layers as needed\n",
    "\n",
    "    def forward(self, node_features, coordinates):\n",
    "\n",
    "        for layer in self.layers:                                                                            \n",
    "            node_features, coordinates = layer(node_features, coordinates)                                      # Update node features and coordinates for each layer in the model\n",
    "        \n",
    "        return node_features, coordinates\n",
    "\n",
    "class DecoyGen(torch.nn.Module):\n",
    "    '''\n",
    "    5 EGNN models run in parallel.\n",
    "    '''\n",
    "    def __init__(self, dims_in=41, decoys=5, **kwargs):\n",
    "        super().__init__()\n",
    "        self.blocks = torch.nn.ModuleList([EGNNModel(node_dim=dims_in, **kwargs) for _ in range(decoys)])\n",
    "        self.decoys = decoys\n",
    "\n",
    "    def forward(self, node_features, coordinates):\n",
    "        geoms = torch.zeros((self.decoys, *coordinates.shape[1:]), device=coordinates.device)\n",
    "\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            geoms[i] = block(node_features, coordinates)[1] # only save geoms\n",
    "\n",
    "        return geoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 EGNN with mask to account for batches with different numbers of nodes**\n",
    "\n",
    "This model uses the mask and can therefore be trained in batches. Model has to be trained on padded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskEGNN(torch.nn.Module):\n",
    "    '''\n",
    "    Singel layer of an EGNN.\n",
    "    '''\n",
    "    def __init__(self, node_dim, message_dim=32):\n",
    "        super().__init__()\n",
    "\n",
    "        edge_input_dim = (node_dim * 2) + 1\n",
    "\n",
    "        self.edge_mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(edge_input_dim, 2*edge_input_dim),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(2*edge_input_dim, message_dim),\n",
    "            torch.nn.SiLU()\n",
    "        )\n",
    "\n",
    "        self.node_mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(node_dim + message_dim, 2*node_dim),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(2*node_dim, node_dim),\n",
    "        )\n",
    "\n",
    "        self.coors_mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(message_dim, 4*message_dim),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(4*message_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, node_features, coordinates, mask):                                                        # We pass in a mask that tells us what nodes to consider and which to ignore.\n",
    "        pair_mask = rearrange(mask, 'b j -> b () j ()') * rearrange(mask, 'b i -> b i () ()')\n",
    "        \n",
    "        rel_coors = rearrange(coordinates, 'b i d -> b i () d') - rearrange(coordinates, 'b j d -> b () j d')  \n",
    "        rel_dist = (rel_coors ** 2).sum(dim=-1, keepdim=True)                                                  \n",
    "\n",
    "        feats_j = rearrange(node_features, 'b j d -> b () j d')      \n",
    "        feats_i = rearrange(node_features, 'b i d -> b i () d')\n",
    "        feats_i, feats_j = torch.broadcast_tensors(feats_i, feats_j)\n",
    "\n",
    "        edge_input = torch.cat((feats_i, feats_j, rel_dist), dim=-1)\n",
    "\n",
    "        m_ij = self.edge_mlp(edge_input)\n",
    "\n",
    "        coor_weights = pair_mask * self.coors_mlp(m_ij)                                                          # We multiply the predicted weight by the mask (masked residue pairs will have zero weight).\n",
    "        coor_weights = rearrange(coor_weights, 'b i j () -> b i j')\n",
    "\n",
    "        rel_coors_normed = rel_coors / rel_dist.clip(min = 1e-8)    \n",
    "\n",
    "        coors_out = coordinates + torch.einsum('b i j, b i j c -> b i c', coor_weights, rel_coors_normed)  \n",
    "\n",
    "        m_i = torch.einsum('b i d, b -> b i d', (pair_mask * m_ij).sum(dim=-2), 1/mask.sum(-1))                 # To average we divide over the length for each batch (length = sum(mask)).\n",
    "\n",
    "        node_mlp_input = torch.cat((node_features, m_i), dim=-1)\n",
    "        node_out = node_features + mask.unsqueeze(-1) * self.node_mlp(node_mlp_input)                             # We set the update for maked residues to zero. \n",
    "\n",
    "        return node_out, coors_out\n",
    "\n",
    "class MaskEGNNModel(torch.nn.Module):\n",
    "    '''\n",
    "    4 EGNN layers joined into one Model\n",
    "    '''\n",
    "    def __init__(self, node_dim, layers=4, message_dim=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = torch.nn.ModuleList([MaskEGNN(node_dim, message_dim = message_dim) for _ in range(layers)])   # Initialise as many EGNN layers as needed\n",
    "\n",
    "    def forward(self, node_features, coordinates, mask):\n",
    "\n",
    "        for layer in self.layers:                                                                            \n",
    "            node_features, coordinates = layer(node_features, coordinates, mask)                                      # Update node features and coordinates for each layer in the model\n",
    "        \n",
    "        return node_features, coordinates\n",
    "\n",
    "class MaskDecoyGen(torch.nn.Module):\n",
    "    '''\n",
    "    5 EGNN models run in parallel.\n",
    "    '''\n",
    "    def __init__(self, dims_in=41, decoys=5, **kwargs):\n",
    "        super().__init__()\n",
    "        self.blocks = torch.nn.ModuleList([MaskEGNNModel(node_dim=dims_in, **kwargs) for _ in range(decoys)])\n",
    "        self.decoys = decoys\n",
    "\n",
    "    def forward(self, node_features, coordinates, mask):\n",
    "        geoms = torch.zeros((self.decoys, *coordinates.shape[1:]), device=coordinates.device)\n",
    "\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            geoms[i] = block(node_features, coordinates, mask)[1] # only save geoms\n",
    "\n",
    "        return geoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train model\n",
    "**3.1 loss functions**\n",
    "\n",
    "The model is initially trained with RMSD as a loss function only. In a second step it is finetune with RMSD and dist check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set loss functions\n",
    "def rmsd(prediction, truth):\n",
    "    dists = (prediction - truth).pow(2).sum(-1)\n",
    "    return torch.sqrt(dists.mean(-1)).mean()\n",
    "\n",
    "def rmsds(preds, true):\n",
    "    return  torch.sort((preds - true).pow(2).sum(-1).mean(-1).pow(1/2))[0]\n",
    "\n",
    "def length_penalty(pred):\n",
    "    return ((((pred[:,1:]-pred[:,:-1])**2).sum(-1).pow(1/2) - 3.802).pow(2)).mean()\n",
    "\n",
    "def different_penalty(pred):\n",
    "    return -(rearrange(pred, \"i n d -> i () n d\") - rearrange(pred, \"j n d -> () j n d\")).pow(2).mean()\n",
    "\n",
    "def dist_check(pred, amino):\n",
    "    err = 0\n",
    "    for i in range(6):\n",
    "        CDR = rearrange(pred[:,amino[0,:,30+i]==1.0], \"d (r a) p -> d a r p\", a = 4)\n",
    "        # CA-CA\n",
    "        err += (((CDR[:,0,1:] - CDR[:,0,:-1]).pow(2).sum(-1).pow(1/2) - 3.82).abs() - 0.12).clamp(0).mean()\n",
    "        # CA-N\n",
    "        err += (((CDR[:,0] - CDR[:,1]).pow(2).sum(-1).pow(1/2) - 1.47).abs() - 0.01).clamp(0).mean()\n",
    "        # CA-C\n",
    "        err += (((CDR[:,0] - CDR[:,2]).pow(2).sum(-1).pow(1/2) - 1.53).abs() - 0.01).clamp(0).mean()\n",
    "        # C-N\n",
    "        err += (((CDR[:,2,:-1] - CDR[:,1,1:]).pow(2).sum(-1).pow(1/2) - 1.34).abs() - 0.01).clamp(0).mean()\n",
    "        # CA-CB\n",
    "        CDR2 = rearrange(pred[:,(amino[0,:,30+i]==1.0) & (amino[0,:,5] != 1.0)], \"d (r a) p -> d a r p\", a = 4)\n",
    "        err += (((CDR2[:,0] - CDR2[:,-1]).pow(2).sum(-1).pow(1/2) - 1.54).abs() - 0.01).clamp(0).mean()\n",
    "\n",
    "    return err\n",
    "\n",
    "def atom_dist(geom):\n",
    "    return ((geom[:,None] - geom[:,:,None]).mean(0).pow(2).sum(-1) + 1e-8).pow(1/2) \n",
    "\n",
    "def atom_dist_penal(geom, pred):\n",
    "    true_ds = atom_dist(geom)\n",
    "    pred_ds = atom_dist(pred)\n",
    "    mask = true_ds < 4.0\n",
    "    return (true_ds-pred_ds)[mask].pow(2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 Training loop**\n",
    "\n",
    "Use this code to train the model without mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train for one epoch\n",
    "def run_epoch(model, optim, train_dataloader, val_dataloader, grad_clip=10.0):\n",
    "    '''\n",
    "    Function to train model for a single epoch\n",
    "    '''\n",
    "    epoch_train_losses = []\n",
    "    epoch_val_losses = []\n",
    "    model.train()                                                      # Set the model to train mode (Should't matter here as we don't have dropout, but good practice to keep in)\n",
    "\n",
    "    for i,data in enumerate(train_dataloader):                         # For each batch of data in the dataset\n",
    "        coordinates, geomouts, node_features = data['geomins'].float(), data['geomouts'].float(), data['encodings'].float()\n",
    "\n",
    "        pred = model(node_features, coordinates)\n",
    "        optim.zero_grad()                                              # Delete old gradients\n",
    "\n",
    "        loss = rmsd(geomouts, pred)\n",
    "        epoch_train_losses.append(loss.item())                         # Store value of loss function for training set\n",
    "\n",
    "        loss.backward()                                                # Calculate loss gradients (pytorch handles this in the background)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)  # Optional: Clip the norm of the gradient (It stops the optimiser from doing very large updates at once)\n",
    "        optim.step()                                                   # Update model weights\n",
    "\n",
    "    with torch.no_grad():                                              # Calculate loss funtion for validation set\n",
    "        model.eval()                                                   # Set the model to eval mode\n",
    "        for i, data in enumerate(val_dataloader):\n",
    "            coordinates, geomouts, node_features, mask = data['geomins'].float(), data['geomouts'].float(), data['encodings'].float(), data['mask'].float()\n",
    "            pred = model(node_features, coordinates, mask)\n",
    "            loss = rmsd(geomouts, pred)\n",
    "            epoch_val_losses.append(loss.item())\n",
    "    \n",
    "    return np.mean(epoch_train_losses), np.mean(epoch_val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this code to train the model with mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train for one epoch with mask\n",
    "def mask_run_epoch(model, optim, train_dataloader, val_dataloader, grad_clip=10.0):\n",
    "    '''\n",
    "    Function to train model for a single epoch with mask\n",
    "    '''\n",
    "    epoch_train_losses = []\n",
    "    epoch_val_losses = []\n",
    "    model.train()                                                      # Set the model to train mode (Should't matter here as we don't have dropout, but good practice to keep in)\n",
    "\n",
    "    for i,data in enumerate(train_dataloader):                         # For each batch of data in the dataset\n",
    "        coordinates, geomouts, node_features, mask = data['geomins'].float(), data['geomouts'].float(), data['encodings'].float(), data['mask'].float()\n",
    "\n",
    "        pred = model(node_features, coordinates, mask)\n",
    "        optim.zero_grad()                                              # Delete old gradients\n",
    "\n",
    "        loss = rmsd(geomouts, pred)\n",
    "        epoch_train_losses.append(loss.item())                         # Store value of loss function for training set\n",
    "\n",
    "        loss.backward()                                                # Calculate loss gradients (pytorch handles this in the background)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)  # Optional: Clip the norm of the gradient (It stops the optimiser from doing very large updates at once)\n",
    "        optim.step()                                                   # Update model weights\n",
    "\n",
    "    with torch.no_grad():                                              # Calculate loss funtion for validation set\n",
    "        model.eval()                                                   # Set the model to eval mode\n",
    "        for i, data in enumerate(val_dataloader):\n",
    "            coordinates, geomouts, node_features, mask = data['geomins'].float(), data['geomouts'].float(), data['encodings'].float(), data['mask'].float()\n",
    "            pred = model(node_features, coordinates, mask)\n",
    "            loss = rmsd(geomouts, pred)\n",
    "            epoch_val_losses.append(loss.item())\n",
    "    \n",
    "    return np.mean(epoch_train_losses), np.mean(epoch_val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimiser, train_dataloader, val_dataloader, n_epochs=5000, patience=150):\n",
    "    '''\n",
    "    Runs run_epoch function a specified number of times and keeps track of loss.\n",
    "    '''\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    print(\" Train |  Val \")\n",
    "    for epoch in track(range(n_epochs), description='Train model'):\n",
    "        train_loss, val_loss = mask_run_epoch(model, optimiser, train_dataloader, val_dataloader)  # Run one epoch and get train and validation loss\n",
    "\n",
    "        train_losses.append(train_loss)                                                    # Store train and validation loss\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if np.min(val_losses) == val_loss:                                                 # If it is the best model on the validation set, save it\n",
    "            torch.save(model.state_dict(), \"best_model\")                                   # This is how you save models in pytorch\n",
    "            epochs_without_improvement = 0\n",
    "\n",
    "        elif epochs_without_improvement < patience:                                        # If the model hasn't improved this epoch store that\n",
    "            epochs_without_improvement += 1\n",
    "        else:                                                                              # If the model hasn't improved in 'patience' epochs stop the training.\n",
    "            break\n",
    "\n",
    "        if train_loss > 1.5*np.min(train_losses):                                          # EGNNs are quite unstable, this reverts the model to a previous state if an epoch blows up\n",
    "            model.load_state_dict(torch.load(\"previous_weights\", map_location=torch.device(device)))\n",
    "            optimiser.load_state_dict(torch.load(\"previous_optim\", map_location=torch.device(device)))\n",
    "        if train_loss == np.min(train_losses):\n",
    "            torch.save(model.state_dict(), \"previous_weights\")        \n",
    "            torch.save(optimiser.state_dict(), \"previous_optim\")  \n",
    "\n",
    "\n",
    "        print(\"{:6.2f} | {:6.2f}\".format(train_loss, train_loss))\n",
    "    \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below actually trains the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train model <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train model \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# torch settings\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "# initialise model\n",
    "model = MaskDecoyGen().to(device = device).float()\n",
    "\n",
    "# set optimiser\n",
    "optimiser = torch.optim.RAdam(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "\n",
    "# Step to actually train the network\n",
    "train_losses, val_losses = train_model(model, optimiser, train_dataloader, val_dataloader, n_epochs=5000, patience=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export losses\n",
    "losses = {'train_loss': train_losses,\n",
    "          'val_loss': val_losses}\n",
    "\n",
    "with open('train_data/losses.json', 'w') as outfile:\n",
    "    json.dump(losses, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3 Analyse trainig losses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(dpi=200)\n",
    "plt.plot(train_losses[10:])        # I don't like to plot the first 10 epochs because they make it harder to see the rest of the data \n",
    "plt.plot(val_losses[10:])\n",
    "plt.legend([\"Train\", \"Val\"])\n",
    "plt.title(\"Evolution of loss during training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use Pytorch lighting for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning\n",
    "from pytorch_lightning.loggers.neptune import NeptuneLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pl_EGNNModel(pytorch_lightning.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.egnnmodel = MaskDecoyGen()\n",
    "\n",
    "    def forward(self, node_encodings, coordinates, mask):\n",
    "\n",
    "        return self.egnnmodel(node_encodings, coordinates, mask)   \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.RAdam(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        predicted_coordinates = self(batch['encodings'], batch['geomins'], batch['mask'])  \n",
    "        loss = rmsd(batch['geomouts'], predicted_coordinates)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx): \n",
    "        predicted_coordinates = self(batch['encodings'], batch['geomins'], batch['mask'])\n",
    "        loss = rmsd(batch['geomouts'],  predicted_coordinates)\n",
    "        return loss\n",
    "\n",
    "    def validation_epoch_end(self, val_step_outputs): # Updated once when validation is called\n",
    "        val_loss = torch.stack(val_step_outputs).detach().cpu().numpy().mean()\n",
    "        self.logger.experiment['evaluation/val_loss'].log(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "ourlogger = NeptuneLogger(api_key=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIyMGI0ZTUzYy0zMTBkLTRjMWMtODhjNS0wNTJmNjA1MzhmOGMifQ==\",\n",
    "              project=\"fspoendlin/ABlooper\",\n",
    "              name=\"Fabian\",\n",
    "              log_model_checkpoints=False,\n",
    "              )\n",
    "\n",
    "trainer = pytorch_lightning.Trainer(\n",
    "    accelerator=\"auto\",  # 'cpu' or 'gpu'\n",
    "    max_epochs=5000,\n",
    "    check_val_every_n_epoch=1,\n",
    "    accumulate_grad_batches=None,\n",
    "    gradient_clip_val=1.0,\n",
    "    logger=ourlogger,\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | egnnmodel | MaskDecoyGen | 662 K \n",
      "-------------------------------------------\n",
      "662 K     Trainable params\n",
      "0         Non-trainable params\n",
      "662 K     Total params\n",
      "2.649     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabian/miniconda3/envs/auto-db-pipeline/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:486: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/Users/fabian/miniconda3/envs/auto-db-pipeline/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:01<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model = pl_EGNNModel()\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b68f9eedec4825490a01d6907fa8139c5284fcb4395b458f0f41fe7d228fceae"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('ab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
